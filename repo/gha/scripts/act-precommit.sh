#!/usr/bin/env bash
# Enhanced act-precommit.sh - Phase 3 Implementation
# GitHub Actions Workflow Testing with Advanced Matrix Capabilities

set -euo pipefail
shopt -s nullglob

# ============================================================================
# CONFIGURATION AND GLOBALS
# ============================================================================

readonly SCRIPT_VERSION="3.0.0-phase3"
readonly SCRIPT_NAME="$(basename "$0")"

# Paths and directories
ROOT="$(git rev-parse --show-toplevel)"
cd "$ROOT"

EVENTS_DIR="${ACT_EVENTS_DIR:-repo/gha/events}"
TESTS_ROOT="${ACT_TESTS_DIR:-repo/gha/tests}"
RUNNER_IMAGE="${ACT_RUNNER_IMAGE:-ghcr.io/catthehacker/ubuntu:act-latest}"
LOG_LEVEL="${ACT_LOG_LEVEL:-INFO}"

# Runtime control
DRY_RUN=0
CRITICAL_ONLY=0
PARALLEL_JOBS="${ACT_PARALLEL_JOBS:-1}"
TIMEOUT="${ACT_TIMEOUT:-300}"
SPECIFIC_WORKFLOW=""
SPECIFIC_EVENT=""

# Status tracking
declare -a EXECUTION_RESULTS=()
declare -A WORKFLOW_EVENTS=()
declare -A COMPATIBILITY_MATRIX=()

# Parallel execution control
declare -a JOB_QUEUE=()
declare -a ACTIVE_JOBS=()
readonly JOB_CONTROL_FILE="/tmp/act-precommit-jobs-$$"

# Performance monitoring
START_TIME=$(date +%s)

# Critical workflows for --critical-only mode (can be overridden by config)
DEFAULT_CRITICAL_WORKFLOWS=(
    "ci"
    "test"
    "release"
    "publish"
)

# Configuration file paths (searched in order)
readonly CONFIG_FILES=(
    ".github/act-precommit.yml"
    ".github/act-precommit.yaml"
    ".act-precommit.yml"
    ".act-precommit.yaml"
    "act-precommit.yml"
    "act-precommit.yaml"
)

# Configuration variables (loaded from config file)
declare -a CRITICAL_WORKFLOWS=("${DEFAULT_CRITICAL_WORKFLOWS[@]}")
declare -A CUSTOM_RUNNER_IMAGES=()
declare -a EVENT_PRIORITY=()

# Advanced configuration
ENABLE_CACHING=true
SKIP_UNCHANGED_WORKFLOWS=true
MAX_WORKFLOWS=20

# Caching variables
readonly CACHE_DIR=".act-precommit-cache"
readonly WORKFLOW_HASH_FILE="$CACHE_DIR/workflow-hashes"

# ============================================================================
# PARALLEL EXECUTION SYSTEM
# ============================================================================

# Job queue management for parallel execution
add_job_to_queue() {
    local test_id="$1"
    local workflow="$2"
    local event="$3"
    local payload="$4"
    local act_command="$5"

    JOB_QUEUE+=("$test_id:$workflow:$event:$payload:$act_command")
}

# Execute jobs in parallel with worker pool
execute_parallel_jobs() {
    local max_jobs="$PARALLEL_JOBS"
    local completed=0
    local total=${#JOB_QUEUE[@]}

    if [[ $total -eq 0 ]]; then
        log WARN "No jobs in queue to execute"
        return 0
    fi

    log INFO "Starting parallel execution with $max_jobs worker(s) for $total job(s)"

    # Create job control file
    echo "0" > "$JOB_CONTROL_FILE"

    # Process job queue
    local job_index=0
    while [[ $completed -lt $total ]]; do
        # Start new jobs up to max_jobs limit
        while [[ ${#ACTIVE_JOBS[@]} -lt $max_jobs ]] && [[ $job_index -lt $total ]]; do
            local job="${JOB_QUEUE[$job_index]}"
            IFS=':' read -r test_id workflow event payload act_command <<< "$job"

            start_background_job "$test_id" "$workflow" "$event" "$payload" "$act_command"
            ACTIVE_JOBS+=("$test_id")
            ((job_index++))

            log DEBUG "Started job $test_id (${#ACTIVE_JOBS[@]}/$max_jobs active)"
        done

        # Wait for at least one job to complete
        if [[ ${#ACTIVE_JOBS[@]} -gt 0 ]]; then
            wait_for_job_completion
            ((completed++))

            # Show progress
            local progress=$((completed * 100 / total))
            log INFO "Progress: $completed/$total jobs completed ($progress%)"
        fi
    done

    # Clean up
    rm -f "$JOB_CONTROL_FILE"
    log SUCCESS "Parallel execution completed: $completed jobs processed"
}

# Start a background job with timeout and monitoring
start_background_job() {
    local test_id="$1"
    local workflow="$2"
    local event="$3"
    local payload="$4"
    local act_command="$5"

    local log_file="/tmp/act-$test_id.log"
    local result_file="/tmp/act-result-$test_id"
    local start_time
    start_time=$(date +%s)

    # Background job execution with timeout
    (
        exec > "$log_file" 2>&1
        echo "Starting test $test_id at $(date)"
        echo "Command: $act_command"
        echo "Timeout: ${TIMEOUT}s"
        echo "---"

        # Execute with timeout
        if timeout "$TIMEOUT" bash -c "$act_command"; then
            exit_code=0
        else
            exit_code=$?
            if [[ $exit_code -eq 124 ]]; then
                echo "ERROR: Test timed out after ${TIMEOUT}s"
                exit_code=2
            fi
        fi

        local end_time
        end_time=$(date +%s)
        local duration=$((end_time - start_time))

        # Write result
        echo "$test_id:$event:$exit_code:$duration" > "$result_file"
        exit $exit_code
    ) &

    local pid=$!
    echo "$test_id:$pid:$start_time" >> "$JOB_CONTROL_FILE.jobs"

    log DEBUG "Background job $test_id started with PID $pid"
}

# Wait for at least one job to complete
wait_for_job_completion() {
    local completed_job=""

    while [[ -z "$completed_job" ]]; do
        # Check for completed jobs
        if [[ -f "$JOB_CONTROL_FILE.jobs" ]]; then
            while IFS=':' read -r test_id pid start_time; do
                if ! kill -0 "$pid" 2>/dev/null; then
                    # Job completed
                    completed_job="$test_id"

                    # Process result
                    local result_file="/tmp/act-result-$test_id"
                    if [[ -f "$result_file" ]]; then
                        local result
                        result=$(cat "$result_file")
                        EXECUTION_RESULTS+=("$result")
                        rm -f "$result_file"
                    else
                        # Job failed without result file
                        local end_time
                        end_time=$(date +%s)
                        local duration=$((end_time - start_time))
                        EXECUTION_RESULTS+=("$test_id:UNKNOWN:1:$duration")
                    fi

                    # Remove from active jobs
                    local new_active=()
                    for active_job in "${ACTIVE_JOBS[@]}"; do
                        if [[ "$active_job" != "$test_id" ]]; then
                            new_active+=("$active_job")
                        fi
                    done
                    ACTIVE_JOBS=("${new_active[@]}")

                    # Update job control file
                    grep -v "^$test_id:" "$JOB_CONTROL_FILE.jobs" > "$JOB_CONTROL_FILE.jobs.tmp" || true
                    mv "$JOB_CONTROL_FILE.jobs.tmp" "$JOB_CONTROL_FILE.jobs"

                    break
                fi
            done < "$JOB_CONTROL_FILE.jobs"
        fi

        if [[ -z "$completed_job" ]]; then
            sleep 0.1  # Brief wait before checking again
        fi
    done

    log DEBUG "Job $completed_job completed"
}

# ============================================================================
# LOGGING SYSTEM
# ============================================================================

log() {
    local level="$1"
    shift
    local timestamp
    timestamp=$(date '+%H:%M:%S')

    case "$level" in
        ERROR) echo "[$timestamp] âŒ ERROR: $*" >&2 ;;
        WARN)  echo "[$timestamp] âš ï¸  WARN:  $*" >&2 ;;
        INFO)  echo "[$timestamp] â„¹ï¸  INFO:  $*" ;;
        DEBUG) [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[$timestamp] ðŸ” DEBUG: $*" ;;
        SUCCESS) echo "[$timestamp] âœ… SUCCESS: $*" ;;
    esac
}

# ============================================================================
# CONFIGURATION FILE MANAGEMENT
# ============================================================================

# Load configuration from YAML/JSON files
load_configuration() {
    local config_file=""

    # Find first available config file
    for file in "${CONFIG_FILES[@]}"; do
        if [[ -f "$file" ]]; then
            config_file="$file"
            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Found configuration file: $config_file" >&2
            break
        fi
    done

    if [[ -z "$config_file" ]]; then
        [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] No configuration file found, using defaults" >&2
        return 0
    fi

    echo "[INFO] Loading configuration from: $config_file"

    # Parse configuration based on file extension (simplified for testing)
    if [[ "$config_file" =~ \.(yml|yaml)$ ]]; then
        # Simple key extraction for testing
        if grep -q "parallel_jobs:" "$config_file"; then
            local pj
            pj=$(grep "parallel_jobs:" "$config_file" | sed 's/.*parallel_jobs:[[:space:]]*\([0-9]*\).*/\1/')
            if [[ "$pj" =~ ^[0-9]+$ ]]; then
                PARALLEL_JOBS="$pj"
                echo "[INFO] Config override: parallel_jobs=$pj"
            fi
        fi
    fi

    return 0
}

# Parse YAML configuration (simplified YAML parser)
parse_yaml_config() {
    local config_file="$1"
    local section=""

    # Add error handling
    set +e

    while IFS= read -r line || [[ -n "$line" ]]; do
        # Skip comments and empty lines
        [[ "$line" =~ ^[[:space:]]*# ]] && continue
        [[ "$line" =~ ^[[:space:]]*$ ]] && continue

        # Detect sections
        if [[ "$line" =~ ^[[:space:]]*([a-zA-Z_][a-zA-Z0-9_]*):.*$ ]]; then
            section="${BASH_REMATCH[1]}"
            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Configuration section: $section" >&2
            continue
        fi

        # Parse key-value pairs
        if [[ "$line" =~ ^[[:space:]]*-[[:space:]]*\"?([^\"]+)\"?[[:space:]]*$ ]]; then
            # Array item
            local item="${BASH_REMATCH[1]}"
            case "$section" in
                critical_workflows)
                    CRITICAL_WORKFLOWS+=("$item")
                    [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Added critical workflow: $item" >&2
                    ;;
                event_priority)
                    EVENT_PRIORITY+=("$item")
                    [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Added event priority: $item" >&2
                    ;;
            esac
        elif [[ "$line" =~ ^[[:space:]]*([a-zA-Z_][a-zA-Z0-9_-]*):.*\"?([^\"]+)\"?.*$ ]]; then
            # Key-value pair
            local key="${BASH_REMATCH[1]}"
            local value="${BASH_REMATCH[2]}"

            case "$section" in
                runner_images)
                    CUSTOM_RUNNER_IMAGES["$key"]="$value"
                    [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Added custom runner: $key -> $value" >&2
                    ;;
                defaults)
                    case "$key" in
                        parallel_jobs)
                            PARALLEL_JOBS="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: parallel_jobs=$value" >&2
                            ;;
                        timeout)
                            TIMEOUT="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: timeout=$value" >&2
                            ;;
                        log_level)
                            LOG_LEVEL="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: log_level=$value" >&2
                            ;;
                    esac
                    ;;
                advanced)
                    case "$key" in
                        enable_caching)
                            ENABLE_CACHING="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: enable_caching=$value" >&2
                            ;;
                        skip_unchanged_workflows)
                            SKIP_UNCHANGED_WORKFLOWS="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: skip_unchanged_workflows=$value" >&2
                            ;;
                        max_workflows)
                            MAX_WORKFLOWS="$value"
                            [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Config override: max_workflows=$value" >&2
                            ;;
                    esac
                    ;;
            esac
        fi
    done < "$config_file"

    # Reset critical workflows if loaded from config
    if [[ ${#CRITICAL_WORKFLOWS[@]} -gt ${#DEFAULT_CRITICAL_WORKFLOWS[@]} ]]; then
        # Remove defaults, keep only config values
        local -a config_workflows=()
        local default_count=${#DEFAULT_CRITICAL_WORKFLOWS[@]}
        for ((i=default_count; i<${#CRITICAL_WORKFLOWS[@]}; i++)); do
            config_workflows+=("${CRITICAL_WORKFLOWS[$i]}")
        done
        CRITICAL_WORKFLOWS=("${config_workflows[@]}")
        [[ "$LOG_LEVEL" == "DEBUG" ]] && echo "[DEBUG] Using config critical workflows: ${CRITICAL_WORKFLOWS[*]}" >&2
    fi

    # Restore error handling
    set -e
}

# Parse JSON configuration (basic JSON parser)
parse_json_config() {
    local config_file="$1"
    log WARN "JSON configuration parsing not yet implemented"
    log INFO "Please use YAML format (.yml or .yaml) for configuration"
}

# Get runner image for platform (with config override support)
get_runner_image() {
    local platform="$1"

    # Check custom runner images first (with safe array access)
    if [[ -v "CUSTOM_RUNNER_IMAGES[$platform]" ]] && [[ -n "${CUSTOM_RUNNER_IMAGES[$platform]}" ]]; then
        echo "${CUSTOM_RUNNER_IMAGES[$platform]}"
        return 0
    fi

    # Fall back to default
    echo "$RUNNER_IMAGE"
}

# Initialize caching system (temporarily simplified for testing)
init_caching() {
    return 0
}

# Get workflow file hash for caching
get_workflow_hash() {
    local workflow_file="$1"
    if [[ -f "$workflow_file" ]]; then
        sha256sum "$workflow_file" 2>/dev/null | cut -d' ' -f1
    else
        echo "missing"
    fi
}

# Check if workflow has changed since last run
workflow_has_changed() {
    local workflow_file="$1"

    if [[ "$ENABLE_CACHING" != "true" ]]; then
        return 0  # Always consider changed if caching disabled
    fi

    local current_hash
    current_hash=$(get_workflow_hash "$workflow_file")
    local cached_hash=""

    if [[ -f "$WORKFLOW_HASH_FILE" ]]; then
        cached_hash=$(grep "^$workflow_file:" "$WORKFLOW_HASH_FILE" 2>/dev/null | cut -d':' -f2)
    fi

    if [[ "$current_hash" != "$cached_hash" ]]; then
        # Update cache
        if [[ -f "$WORKFLOW_HASH_FILE" ]]; then
            sed -i.bak "/^$workflow_file:/d" "$WORKFLOW_HASH_FILE"
        fi
        echo "$workflow_file:$current_hash" >> "$WORKFLOW_HASH_FILE"
        return 0  # Changed
    else
        return 1  # Not changed
    fi
}

# Enhanced git workflow detection with change analysis
get_enhanced_workflows_to_test() {
    local -a workflows=()
    local -a changed_files=()

    # Get all changed files in this commit
    mapfile -t changed_files < <(git diff --cached --name-only --diff-filter=ACMRTUXB || true)

    if [[ ${#changed_files[@]} -eq 0 ]]; then
        log DEBUG "No files changed in this commit"
        return 0
    fi

    log DEBUG "Found ${#changed_files[@]} changed files"

    # Find workflow files that changed
    for file in "${changed_files[@]}"; do
        if [[ "$file" =~ ^\.github/workflows/.*\.(yml|yaml)$ ]]; then
            workflows+=("$file")
            log DEBUG "Direct workflow change: $file"
        fi
    done

    # If no direct workflow changes, check for code changes that might affect workflows
    if [[ ${#workflows[@]} -eq 0 ]] && [[ "$SKIP_UNCHANGED_WORKFLOWS" != "true" ]]; then
        log DEBUG "No workflow changes, checking for code changes affecting workflows"

        # Check if any workflow would be triggered by these file changes
        for workflow_file in .github/workflows/*.{yml,yaml}; do
            if [[ -f "$workflow_file" ]] && should_test_workflow_for_changes "$workflow_file" "${changed_files[@]}"; then
                workflows+=("$workflow_file")
                log DEBUG "Workflow affected by code changes: $workflow_file"
            fi
        done
    fi

    # Limit number of workflows if configured
    if [[ ${#workflows[@]} -gt $MAX_WORKFLOWS ]]; then
        log WARN "Limiting workflows from ${#workflows[@]} to $MAX_WORKFLOWS"
        workflows=("${workflows[@]:0:$MAX_WORKFLOWS}")
    fi

    printf '%s\n' "${workflows[@]}"
}

# Check if workflow should be tested based on file changes
should_test_workflow_for_changes() {
    local workflow_file="$1"
    shift
    local changed_files=("$@")

    # Simple heuristic: if any Python files changed and workflow mentions Python, test it
    for file in "${changed_files[@]}"; do
        case "$file" in
            *.py|pyproject.toml|requirements*.txt|setup.py|setup.cfg)
                if grep -q -i "python\|py\|pytest\|pip" "$workflow_file" 2>/dev/null; then
                    return 0
                fi
                ;;
            *.js|*.ts|package*.json|*.json|yarn.lock)
                if grep -q -i "node\|npm\|yarn\|javascript\|typescript" "$workflow_file" 2>/dev/null; then
                    return 0
                fi
                ;;
            *.md|docs/*|*.rst)
                if grep -q -i "docs\|documentation\|sphinx\|mkdocs" "$workflow_file" 2>/dev/null; then
                    return 0
                fi
                ;;
        esac
    done

    return 1
}

# ============================================================================
# YAML PARSING FUNCTIONS
# ============================================================================

# Extract supported events from workflow YAML files
parse_workflow_events() {
    local workflow_file="$1"
    local workflow_name
    workflow_name=$(basename "$workflow_file" .yml)
    workflow_name=$(basename "$workflow_name" .yaml)

    # Hardcoded event mappings for our known workflows (temporary solution)
    # TODO: Replace with proper YAML parsing
    case "$workflow_name" in
        "ci")
            echo "push"
            echo "pull_request"
            ;;
        "test")
            echo "push"
            echo "pull_request"
            echo "workflow_call"
            ;;
        "docs")
            echo "push"
            echo "pull_request"
            echo "release"
            echo "workflow_dispatch"
            ;;
        "coverage")
            echo "push"
            echo "pull_request"
            ;;
        "performance")
            echo "push"
            echo "pull_request"
            echo "workflow_dispatch"
            ;;
        "publish")
            echo "workflow_dispatch"
            ;;
        "release")
            echo "push"
            echo "release"
            echo "workflow_dispatch"
            ;;
        "release-please")
            echo "push"
            ;;
        "release-staged")
            echo "push"
            ;;
        "example-release-process")
            echo "workflow_dispatch"
            ;;
        "conventional-commits")
            echo "pull_request"
            ;;
        "validate-release")
            echo "workflow_call"
            echo "pull_request"
            ;;
        *)
            # Default events for unknown workflows
            echo "push"
            echo "pull_request"
            ;;
    esac
}

# Build compatibility matrix for all workflows
build_compatibility_matrix() {
    log INFO "Building workflow-event compatibility matrix..."

    for workflow_file in .github/workflows/*.{yml,yaml}; do
        [[ -f "$workflow_file" ]] || continue

        local workflow_name
        workflow_name=$(basename "$workflow_file")
        workflow_name="${workflow_name%.*}"

        log DEBUG "Processing workflow: $workflow_name"

        local -a supported_events
        mapfile -t supported_events < <(parse_workflow_events "$workflow_file")

        if [[ ${#supported_events[@]} -gt 0 ]]; then
            WORKFLOW_EVENTS["$workflow_name"]="${supported_events[*]}"
            log DEBUG "Workflow $workflow_name supports: ${supported_events[*]}"

            # Build compatibility matrix
            for event in "${supported_events[@]}"; do
                COMPATIBILITY_MATRIX["${workflow_name}:${event}"]=1
            done
        else
            log WARN "No events found for workflow: $workflow_name"
        fi
    done
}

# Check if workflow supports specific event
is_event_compatible() {
    local workflow="$1"
    local event="$2"
    [[ "${COMPATIBILITY_MATRIX["${workflow}:${event}"]:-0}" == "1" ]]
}

# ============================================================================
# PAYLOAD MANAGEMENT
# ============================================================================

# Find best payload for workflow-event combination
find_best_payload() {
    local workflow="$1"
    local event="$2"
    local test_dir="$TESTS_ROOT/$workflow"

    # Priority order for payload selection
    local payload_candidates=(
        "$test_dir/$event.json"                    # Specific workflow + event
        "$EVENTS_DIR/$event.json"                  # Global event payload
    )

    for payload in "${payload_candidates[@]}"; do
        if [[ -f "$payload" ]]; then
            echo "$payload"
            return 0
        fi
    done

    # No payload found
    return 1
}

# ============================================================================
# EXECUTION ENGINE
# ============================================================================

# Execute single workflow-event combination
execute_workflow_test() {
    local workflow_file="$1"
    local event="$2"
    local payload="$3"
    local test_id="$4"

    local start_time
    start_time=$(date +%s)

    local workflow_name
    workflow_name=$(basename "$workflow_file")
    workflow_name="${workflow_name%.*}"

    log INFO "[$test_id] Testing $workflow_name with $event event"

    # Build act command
    local act_cmd=(
        act "$event"
        -W "$workflow_file"
    )

    if [[ -n "$payload" ]]; then
        act_cmd+=(-e "$payload")
        log DEBUG "[$test_id] Using payload: $payload"
    else
        log DEBUG "[$test_id] No payload (default event data)"
    fi

    # Add runner flags with custom image support
    local ubuntu_latest_image
    ubuntu_latest_image=$(get_runner_image "ubuntu-latest")
    local ubuntu_2204_image
    ubuntu_2204_image=$(get_runner_image "ubuntu-22.04")
    local ubuntu_2004_image
    ubuntu_2004_image=$(get_runner_image "ubuntu-20.04")

    local runner_flags=(
        -P "ubuntu-latest=$ubuntu_latest_image"
        -P "ubuntu-22.04=$ubuntu_2204_image"
        -P "ubuntu-20.04=$ubuntu_2004_image"
    )
    act_cmd+=("${runner_flags[@]}")

    # Add any additional args
    if [[ -n "${ACT_ARGS:-}" ]]; then
        # shellcheck disable=SC2206
        act_cmd+=(${ACT_ARGS})
    fi

    if [[ $DRY_RUN -eq 1 ]]; then
        log INFO "[$test_id] DRY-RUN: ${act_cmd[*]}"
        EXECUTION_RESULTS+=("$test_id:DRY_RUN:0:0")
        return 0
    fi

    # Execute with timeout
    local exit_code=0
    if timeout "$TIMEOUT" "${act_cmd[@]}" > "/tmp/act-${test_id}.log" 2>&1; then
        exit_code=0
        log SUCCESS "[$test_id] Workflow executed successfully"
    else
        exit_code=$?
        log ERROR "[$test_id] Workflow failed with exit code: $exit_code"
        # Show last 10 lines of error log
        if [[ -f "/tmp/act-${test_id}.log" ]]; then
            log ERROR "[$test_id] Last 10 lines of output:"
            tail -n 10 "/tmp/act-${test_id}.log" | sed 's/^/    /' >&2
        fi
    fi

    local end_time
    end_time=$(date +%s)
    local duration=$((end_time - start_time))

    EXECUTION_RESULTS+=("$test_id:$event:$exit_code:$duration")

    return $exit_code
}

# ============================================================================
# WORKFLOW SELECTION AND FILTERING
# ============================================================================

# Get workflows to test based on git changes or user selection
get_workflows_to_test() {
    local -a workflows=()

    if [[ -n "$SPECIFIC_WORKFLOW" ]]; then
        # User specified specific workflow
        if [[ -f ".github/workflows/${SPECIFIC_WORKFLOW}.yml" ]]; then
            workflows+=(".github/workflows/${SPECIFIC_WORKFLOW}.yml")
        elif [[ -f ".github/workflows/${SPECIFIC_WORKFLOW}.yaml" ]]; then
            workflows+=(".github/workflows/${SPECIFIC_WORKFLOW}.yaml")
        else
            log ERROR "Workflow not found: $SPECIFIC_WORKFLOW"
            exit 1
        fi
    else
        # Detect changed workflows from git or use all workflows for critical-only mode
        if [[ $CRITICAL_ONLY -eq 1 ]]; then
            # Critical-only mode: test all critical workflows
            log INFO "Critical-only mode: testing essential workflows"
            for workflow_file in .github/workflows/*.{yml,yaml}; do
                if [[ -f "$workflow_file" ]]; then
                    local workflow_name
                    workflow_name=$(basename "$workflow_file")
                    workflow_name="${workflow_name%.*}"

                    if is_critical_workflow "$workflow_name"; then
                        workflows+=("$workflow_file")
                        log DEBUG "Added critical workflow: $workflow_name"
                    fi
                fi
            done

            if [[ ${#workflows[@]} -eq 0 ]]; then
                log WARN "No critical workflows found"
                exit 0
            fi
        else
            # Normal mode: detect changed workflows from git
            mapfile -t workflows < <(git diff --cached --name-only --diff-filter=ACMRTUXB \
                | grep -E '^\.github/workflows/.*\.(yml|yaml)$' || true)

            if [[ ${#workflows[@]} -eq 0 ]]; then
                log INFO "No workflow changes detected"
                exit 0
            fi
        fi
    fi

    # Apply critical-only filtering even when specific workflow is provided
    if [[ $CRITICAL_ONLY -eq 1 ]] && [[ -n "$SPECIFIC_WORKFLOW" ]]; then
        if ! is_critical_workflow "$SPECIFIC_WORKFLOW"; then
            log ERROR "Workflow '$SPECIFIC_WORKFLOW' is not marked as critical"
            log INFO "Critical workflows: ${CRITICAL_WORKFLOWS[*]}"
            exit 1
        fi
    fi

    printf '%s\n' "${workflows[@]}"
}

# ============================================================================
# MAIN EXECUTION LOGIC
# ============================================================================

# Main workflow testing function
test_workflows() {
    log INFO "Starting workflow testing (Version $SCRIPT_VERSION)"

    # Build compatibility matrix
    build_compatibility_matrix

    # Get workflows to test
    local -a workflows_to_test
    mapfile -t workflows_to_test < <(get_workflows_to_test)

    if [[ ${#workflows_to_test[@]} -eq 0 ]]; then
        log INFO "No workflows to test"
        return 0
    fi

    log INFO "Testing ${#workflows_to_test[@]} workflow(s)"

    local test_counter=0
    local total_failures=0

    # Process each workflow
    for workflow_file in "${workflows_to_test[@]}"; do
        local workflow_name
        workflow_name=$(basename "$workflow_file")
        workflow_name="${workflow_name%.*}"

        log INFO "Processing workflow: $workflow_name ($workflow_file)"

        # Get supported events for this workflow
        local supported_events="${WORKFLOW_EVENTS["$workflow_name"]:-}"
        if [[ -z "$supported_events" ]]; then
            log WARN "No supported events found for $workflow_name, using defaults"
            supported_events="push pull_request"
        fi

        # Convert to array
        local -a events_array
        read -ra events_array <<< "$supported_events"

        # Filter events if user specified
        if [[ -n "$SPECIFIC_EVENT" ]]; then
            if is_event_compatible "$workflow_name" "$SPECIFIC_EVENT"; then
                events_array=("$SPECIFIC_EVENT")
            else
                log ERROR "Event $SPECIFIC_EVENT not supported by workflow $workflow_name"
                log INFO "Supported events: $supported_events"
                continue
            fi
        fi

        # Queue jobs for each event
        local workflow_had_tests=0
        for event in "${events_array[@]}"; do
            ((test_counter++))
            local test_id="test-$(printf "%03d" $test_counter)"

            # Find payload for this combination
            local payload=""
            if payload=$(find_best_payload "$workflow_name" "$event"); then
                log DEBUG "Using payload: $payload"
            else
                log DEBUG "No payload found for $workflow_name:$event, using default"
            fi

            # Build act command for parallel execution with custom runner support
            local act_cmd="act $event -W $workflow_file"
            if [[ -n "$payload" ]]; then
                act_cmd="$act_cmd -e $payload"
            fi

            # Add runner flags with custom image support
            local ubuntu_latest_image
            ubuntu_latest_image=$(get_runner_image "ubuntu-latest")
            local ubuntu_2204_image
            ubuntu_2204_image=$(get_runner_image "ubuntu-22.04")
            local ubuntu_2004_image
            ubuntu_2004_image=$(get_runner_image "ubuntu-20.04")

            act_cmd="$act_cmd -P ubuntu-latest=$ubuntu_latest_image"
            act_cmd="$act_cmd -P ubuntu-22.04=$ubuntu_2204_image"
            act_cmd="$act_cmd -P ubuntu-20.04=$ubuntu_2004_image"

            # Add any additional args
            if [[ -n "${ACT_ARGS:-}" ]]; then
                act_cmd="$act_cmd ${ACT_ARGS}"
            fi

            # Add to job queue instead of executing immediately
            add_job_to_queue "$test_id" "$workflow_name" "$event" "$payload" "$act_cmd"
            workflow_had_tests=1
        done

        if [[ $workflow_had_tests -eq 0 ]]; then
            log WARN "No compatible events tested for workflow: $workflow_name"
        fi
    done

    # Execute all queued jobs
    if [[ $DRY_RUN -eq 1 ]]; then
        log INFO "Dry run mode - showing queued commands:"
        for job in "${JOB_QUEUE[@]}"; do
            IFS=':' read -r test_id workflow event payload act_command <<< "$job"
            log INFO "[$test_id] DRY-RUN: $act_command"
            EXECUTION_RESULTS+=("$test_id:DRY_RUN:0:0")
        done
    elif [[ $PARALLEL_JOBS -gt 1 ]]; then
        log INFO "Executing $test_counter tests in parallel (max $PARALLEL_JOBS concurrent)"
        execute_parallel_jobs
    else
        log INFO "Executing $test_counter tests sequentially"
        # Sequential execution for single-threaded mode
        for job in "${JOB_QUEUE[@]}"; do
            IFS=':' read -r test_id workflow event payload act_command <<< "$job"
            local start_time
            start_time=$(date +%s)

            log INFO "[$test_id] Testing $workflow with $event event"

            local exit_code=0
            local log_file="/tmp/act-$test_id.log"

            if timeout "$TIMEOUT" bash -c "$act_command" > "$log_file" 2>&1; then
                exit_code=0
                log SUCCESS "[$test_id] Workflow executed successfully"
            else
                exit_code=$?
                log ERROR "[$test_id] Workflow failed with exit code: $exit_code"
                if [[ $exit_code -eq 124 ]]; then
                    log ERROR "[$test_id] Test timed out after ${TIMEOUT}s"
                    exit_code=2
                fi
                # Show last 10 lines of error log
                if [[ -f "$log_file" ]]; then
                    log ERROR "[$test_id] Last 10 lines of output:"
                    tail -n 10 "$log_file" | sed 's/^/    /' >&2
                fi
            fi

            local end_time
            end_time=$(date +%s)
            local duration=$((end_time - start_time))

            EXECUTION_RESULTS+=("$test_id:$event:$exit_code:$duration")

            if [[ $exit_code -ne 0 ]]; then
                ((total_failures++))
            fi
        done
    fi

    # Report results
    report_execution_results

    # Calculate total failures from execution results
    total_failures=0
    for result in "${EXECUTION_RESULTS[@]}"; do
        IFS=':' read -r test_id event exit_code duration <<< "$result"
        if [[ "$exit_code" != "0" ]] && [[ "$exit_code" != "DRY_RUN" ]]; then
            ((total_failures++))
        fi
    done

    if [[ $total_failures -gt 0 ]]; then
        log ERROR "Testing completed with $total_failures failure(s)"
        return 1
    else
        log SUCCESS "All workflow tests passed!"
        return 0
    fi
}

# ============================================================================
# REPORTING
# ============================================================================

# Generate execution report
report_execution_results() {
    if [[ ${#EXECUTION_RESULTS[@]} -eq 0 ]]; then
        log INFO "No test results to report"
        return
    fi

    log INFO "=== EXECUTION SUMMARY ==="

    local total_tests=0
    local successful_tests=0
    local failed_tests=0
    local total_duration=0

    printf "%-8s %-20s %-8s %-10s\n" "TEST-ID" "EVENT" "STATUS" "DURATION"
    printf "%-8s %-20s %-8s %-10s\n" "-------" "--------------------" "--------" "----------"

    for result in "${EXECUTION_RESULTS[@]}"; do
        IFS=':' read -r test_id event exit_code duration <<< "$result"

        ((total_tests++))
        ((total_duration += duration))

        local status
        if [[ "$exit_code" == "0" ]]; then
            status="âœ… PASS"
            ((successful_tests++))
        else
            status="âŒ FAIL"
            ((failed_tests++))
        fi

        printf "%-8s %-20s %-8s %-10s\n" "$test_id" "$event" "$status" "${duration}s"
    done

    echo

    # Calculate and display performance metrics
    local end_time
    end_time=$(date +%s)
    local wall_clock_time=$((end_time - START_TIME))

    log INFO "Tests: $total_tests, Passed: $successful_tests, Failed: $failed_tests"
    log INFO "Total execution time: ${total_duration}s"
    log INFO "Wall clock time: ${wall_clock_time}s"

    # Performance analysis
    if [[ $total_tests -gt 0 ]]; then
        local avg_test_time=$((total_duration / total_tests))
        log INFO "Average test time: ${avg_test_time}s"

        if [[ $PARALLEL_JOBS -gt 1 ]] && [[ $wall_clock_time -gt 0 ]]; then
            local denominator=$((wall_clock_time * PARALLEL_JOBS))
            if [[ $denominator -gt 0 ]]; then
                local efficiency=$((total_duration * 100 / denominator))
                log INFO "Parallel efficiency: ${efficiency}% (${PARALLEL_JOBS} workers)"

                if [[ $efficiency -lt 50 ]]; then
                    log WARN "Low parallel efficiency - consider reducing worker count"
                fi
            fi
        fi
    fi

    if [[ $failed_tests -gt 0 ]]; then
        log ERROR "Check /tmp/act-*.log files for detailed error information"
    fi
}

# ============================================================================
# CLI ARGUMENT PARSING
# ============================================================================

show_help() {
    cat << EOF
$SCRIPT_NAME v$SCRIPT_VERSION - Enhanced GitHub Actions Workflow Testing

USAGE:
    $SCRIPT_NAME [OPTIONS]

DESCRIPTION:
    Tests GitHub Actions workflows locally using 'act' with intelligent event
    detection, compatibility checking, and advanced execution capabilities.

OPTIONS:
    -h, --help              Show this help message
    -v, --version           Show script version
    -n, --dry-run           Show what would be executed without running
    -c, --critical-only     Test only critical workflows (main CI/CD flows)
    -w, --workflow=NAME     Test specific workflow by name (without .yml extension)
    -e, --event=TYPE        Test specific event type (push, pull_request, etc.)
    -p, --parallel=JOBS     Number of parallel test jobs (default: 1)
    -t, --timeout=SECONDS   Timeout for each test (default: 300)
    -d, --debug             Enable debug logging
    -q, --quiet             Reduce output verbosity

ENVIRONMENT VARIABLES:
    ACT_RUNNER_IMAGE        Docker image for act runner (default: catthehacker/ubuntu:act-latest)
    ACT_EVENTS_DIR          Directory containing event payloads (default: repo/gha/events)
    ACT_TESTS_DIR           Directory containing test payloads (default: repo/gha/tests)
    ACT_ARGS                Additional arguments to pass to act
    ACT_PARALLEL_JOBS       Default parallel job count
    ACT_TIMEOUT             Default timeout in seconds
    ACT_LOG_LEVEL          Logging level (DEBUG, INFO, WARN, ERROR)
    SKIP_ACT               Set to 1 to skip all testing

EXAMPLES:
    # Test all changed workflows
    $SCRIPT_NAME

    # Test specific workflow
    $SCRIPT_NAME --workflow=ci

    # Test with specific event
    $SCRIPT_NAME --workflow=test --event=pull_request

    # Dry run with debug output
    $SCRIPT_NAME --dry-run --debug

    # Parallel execution
    $SCRIPT_NAME --parallel=3

CONFIGURATION FILES:
    Configuration files are searched in the following order:
    1. .github/act-precommit.yml
    2. .github/act-precommit.yaml
    3. .act-precommit.yml
    4. .act-precommit.yaml
    5. act-precommit.yml
    6. act-precommit.yaml

    Example configuration:
    runner_images:
      ubuntu-latest: "ghcr.io/catthehacker/ubuntu:act-latest"
    critical_workflows:
      - "ci"
      - "test"
    defaults:
      parallel_jobs: 3
      timeout: 300

EXIT CODES:
    0    All tests passed
    1    One or more tests failed
    2    Configuration or setup error

For more information, see: https://nektosact.com/
EOF
}

parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -v|--version)
                echo "$SCRIPT_NAME version $SCRIPT_VERSION"
                exit 0
                ;;
            -n|--dry-run)
                DRY_RUN=1
                log INFO "Dry run mode enabled"
                shift
                ;;
            -c|--critical-only)
                CRITICAL_ONLY=1
                log INFO "Critical-only mode enabled"
                shift
                ;;
            -w|--workflow)
                SPECIFIC_WORKFLOW="$2"
                log INFO "Testing specific workflow: $SPECIFIC_WORKFLOW"
                shift 2
                ;;
            --workflow=*)
                SPECIFIC_WORKFLOW="${1#*=}"
                log INFO "Testing specific workflow: $SPECIFIC_WORKFLOW"
                shift
                ;;
            -e|--event)
                SPECIFIC_EVENT="$2"
                log INFO "Testing specific event: $SPECIFIC_EVENT"
                shift 2
                ;;
            --event=*)
                SPECIFIC_EVENT="${1#*=}"
                log INFO "Testing specific event: $SPECIFIC_EVENT"
                shift
                ;;
            -p|--parallel)
                PARALLEL_JOBS="$2"
                log INFO "Parallel jobs set to: $PARALLEL_JOBS"
                shift 2
                ;;
            --parallel=*)
                PARALLEL_JOBS="${1#*=}"
                log INFO "Parallel jobs set to: $PARALLEL_JOBS"
                shift
                ;;
            -t|--timeout)
                TIMEOUT="$2"
                log INFO "Timeout set to: $TIMEOUT seconds"
                shift 2
                ;;
            --timeout=*)
                TIMEOUT="${1#*=}"
                log INFO "Timeout set to: $TIMEOUT seconds"
                shift
                ;;
            -d|--debug)
                LOG_LEVEL="DEBUG"
                log INFO "Debug logging enabled"
                shift
                ;;
            -q|--quiet)
                LOG_LEVEL="ERROR"
                shift
                ;;
            *)
                log ERROR "Unknown option: $1"
                echo "Use --help for usage information"
                exit 2
                ;;
        esac
    done

    # Validate arguments
    validate_arguments
}

# Validate command line arguments
validate_arguments() {
    # Validate parallel jobs
    if ! [[ "$PARALLEL_JOBS" =~ ^[1-9][0-9]*$ ]]; then
        log ERROR "Invalid parallel jobs value: $PARALLEL_JOBS (must be positive integer)"
        exit 2
    fi

    if [[ $PARALLEL_JOBS -gt 10 ]]; then
        log WARN "High parallel job count ($PARALLEL_JOBS) may overwhelm system resources"
    fi

    # Validate timeout
    if ! [[ "$TIMEOUT" =~ ^[1-9][0-9]*$ ]]; then
        log ERROR "Invalid timeout value: $TIMEOUT (must be positive integer)"
        exit 2
    fi

    if [[ $TIMEOUT -lt 60 ]]; then
        log WARN "Short timeout ($TIMEOUT s) may cause false failures"
    fi

    # Check for act command
    if [[ $DRY_RUN -eq 0 ]] && ! command -v act >/dev/null 2>&1; then
        log ERROR "'act' command not found. Install from https://nektosact.com/"
        exit 2
    fi

    # Validate specific event if provided
    if [[ -n "$SPECIFIC_EVENT" ]]; then
        case "$SPECIFIC_EVENT" in
            push|pull_request|release|workflow_dispatch|workflow_call)
                # Valid events
                ;;
            *)
                log ERROR "Invalid event type: $SPECIFIC_EVENT"
                log INFO "Valid events: push, pull_request, release, workflow_dispatch, workflow_call"
                exit 2
                ;;
        esac
    fi
}

# Check if workflow is critical
is_critical_workflow() {
    local workflow_name="$1"
    for critical in "${CRITICAL_WORKFLOWS[@]}"; do
        if [[ "$workflow_name" == "$critical" ]]; then
            return 0
        fi
    done
    return 1
}

# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

main() {
    # Load configuration file first
    load_configuration

    # Initialize caching system
    init_caching

    # Parse command line arguments (can override config)
    parse_arguments "$@"

    # Check for skip flag
    if [[ "${SKIP_ACT:-0}" == "1" ]]; then
        log INFO "SKIP_ACT=1; skipping all tests"
        exit 0
    fi

    # Check if act is installed
    if ! command -v act >/dev/null 2>&1; then
        log ERROR "'act' not installed; skipping. See https://nektosact.com/"
        exit 0
    fi

    # Validate parallel jobs setting
    if ! [[ "$PARALLEL_JOBS" =~ ^[1-9][0-9]*$ ]] || [[ $PARALLEL_JOBS -gt 10 ]]; then
        log ERROR "Invalid parallel jobs setting: $PARALLEL_JOBS (must be 1-10)"
        exit 2
    fi

    # Validate timeout setting
    if ! [[ "$TIMEOUT" =~ ^[1-9][0-9]*$ ]] || [[ $TIMEOUT -lt 30 ]] || [[ $TIMEOUT -gt 3600 ]]; then
        log ERROR "Invalid timeout setting: $TIMEOUT (must be 30-3600 seconds)"
        exit 2
    fi

    # Start testing
    if test_workflows; then
        exit 0
    else
        exit 1
    fi
}

# ============================================================================
# SCRIPT EXECUTION
# ============================================================================

# Only run main if script is executed directly (not sourced)
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
